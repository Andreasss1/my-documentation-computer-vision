# Kode Lanjutan: Inferensi pada Data Test dengan Upload, Visualisasi Heatmap, dan Indikator Anomali

# Install dependencies (jika belum diinstal dari kode sebelumnya)
!pip install torch torchvision torchaudio
!pip install timm
!pip install opencv-python-headless
!pip install matplotlib seaborn
!pip install scikit-learn
!pip install Pillow
!pip install requests
!pip install albumentations

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader
import cv2
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import os
from PIL import Image
import albumentations as A
from albumentations.pytorch import ToTensorV2
from google.colab import files
import warnings
warnings.filterwarnings('ignore')

# Set device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"Using device: {device}")

# Kelas Model dari Kode Sebelumnya (kopi untuk kelengkapan)
class PatchDescriptor(nn.Module):
    """Patch Descriptor untuk feature extraction"""
    def __init__(self, input_dim=3, hidden_dim=256, output_dim=384):
        super().__init__()
        self.conv1 = nn.Conv2d(input_dim, 64, 3, padding=1)
        self.conv2 = nn.Conv2d(64, 128, 3, padding=1)
        self.conv3 = nn.Conv2d(128, 256, 3, padding=1)
        self.conv4 = nn.Conv2d(256, output_dim, 3, padding=1)
        
        self.pool = nn.MaxPool2d(2, 2)
        self.relu = nn.ReLU(inplace=True)
        self.dropout = nn.Dropout(0.1)
        
    def forward(self, x):
        x = self.relu(self.conv1(x))
        x = self.pool(x)
        x = self.relu(self.conv2(x))
        x = self.pool(x)
        x = self.relu(self.conv3(x))
        x = self.pool(x)
        x = self.relu(self.conv4(x))
        return x

class StudentTeacherNet(nn.Module):
    """Student-Teacher network untuk EfficientAD"""
    def __init__(self, input_dim=3, feature_dim=384):
        super().__init__()
        self.teacher = PatchDescriptor(input_dim, output_dim=feature_dim)
        self.student = PatchDescriptor(input_dim, output_dim=feature_dim)
        
        # Freeze teacher network
        for param in self.teacher.parameters():
            param.requires_grad = False
            
    def forward(self, x):
        teacher_features = self.teacher(x)
        student_features = self.student(x)
        return teacher_features, student_features

class EfficientAD_M(nn.Module):
    """EfficientAD-M model"""
    def __init__(self, input_size=256, feature_dim=384):
        super().__init__()
        self.input_size = input_size
        self.feature_dim = feature_dim
        
        # Student-Teacher networks
        self.st_net = StudentTeacherNet(input_dim=3, feature_dim=feature_dim)
        
        # Autoencoder untuk reconstruction
        self.encoder = nn.Sequential(
            nn.Conv2d(3, 32, 4, 2, 1),
            nn.LeakyReLU(0.2),
            nn.Conv2d(32, 64, 4, 2, 1),
            nn.LeakyReLU(0.2),
            nn.Conv2d(64, 128, 4, 2, 1),
            nn.LeakyReLU(0.2),
            nn.Conv2d(128, 256, 4, 2, 1),
            nn.LeakyReLU(0.2),
        )
        
        self.decoder = nn.Sequential(
            nn.ConvTranspose2d(256, 128, 4, 2, 1),
            nn.ReLU(),
            nn.ConvTranspose2d(128, 64, 4, 2, 1),
            nn.ReLU(),
            nn.ConvTranspose2d(64, 32, 4, 2, 1),
            nn.ReLU(),
            nn.ConvTranspose2d(32, 3, 4, 2, 1),
            nn.Sigmoid(),
        )
        
    def forward(self, x):
        # Student-Teacher features
        teacher_feat, student_feat = self.st_net(x)
        
        # Autoencoder reconstruction
        encoded = self.encoder(x)
        reconstructed = self.decoder(encoded)
        
        return {
            'teacher_features': teacher_feat,
            'student_features': student_feat,
            'reconstructed': reconstructed,
            'encoded': encoded
        }
    
    def compute_anomaly_map(self, x):
        """Compute anomaly heatmap"""
        with torch.no_grad():
            outputs = self.forward(x)
            
            # Student-Teacher anomaly score
            teacher_feat = outputs['teacher_features']
            student_feat = outputs['student_features']
            st_diff = torch.mean((teacher_feat - student_feat) ** 2, dim=1, keepdim=True)
            
            # Reconstruction anomaly score
            recon_diff = torch.mean((x - outputs['reconstructed']) ** 2, dim=1, keepdim=True)
            
            # Combine anomaly scores
            st_map = F.interpolate(st_diff, size=(self.input_size, self.input_size), mode='bilinear', align_corners=False)
            recon_map = F.interpolate(recon_diff, size=(self.input_size, self.input_size), mode='bilinear', align_corners=False)
            
            # Weighted combination
            anomaly_map = 0.7 * st_map + 0.3 * recon_map
            
            return anomaly_map.squeeze().cpu().numpy()

# Transformasi untuk data test (tanpa augmentasi)
test_transform = A.Compose([
    A.Resize(256, 256),
    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
    ToTensorV2()
])

# Fungsi untuk upload data test
def upload_test_data():
    """Upload gambar test ke /content/test_data"""
    print("Upload gambar test (ponsel dengan kemungkinan defect)...")
    !mkdir -p /content/test_data
    uploaded = files.upload()
    for filename in uploaded.keys():
        !mv {filename} /content/test_data/
    print(f"{len(uploaded)} gambar test diupload ke /content/test_data.")

# Dataset class untuk data test
class CustomTestDataset(Dataset):
    def __init__(self, root_dir='/content/test_data', transform=None):
        self.root_dir = root_dir
        self.transform = transform
        self.images = []
        
        # Mengumpulkan semua gambar dari direktori /content/test_data
        for img_path in os.listdir(self.root_dir):
            if img_path.endswith(('.png', '.jpg', '.jpeg')):
                self.images.append(os.path.join(self.root_dir, img_path))
        
        if len(self.images) == 0:
            raise ValueError("No images found in /content/test_data. Please upload test images.")
    
    def __len__(self):
        return len(self.images)
    
    def __getitem__(self, idx):
        # Load image
        image_path = self.images[idx]
        image = cv2.imread(image_path)
        if image is None:
            image = np.random.randint(0, 255, (256, 256, 3), dtype=np.uint8)
        else:
            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            image = cv2.resize(image, (256, 256))
        
        # Simpan gambar asli untuk visualisasi
        original_image = image.copy()
        
        # Apply transforms
        if self.transform:
            transformed = self.transform(image=image)
            image = transformed['image']
        
        return {
            'image': image,
            'original_image': original_image,
            'path': image_path
        }

# Fungsi untuk memuat model yang telah dilatih
def load_model(model_path='results/efficientad_model.pth'):
    """Load trained EfficientAD-M model"""
    model = EfficientAD_M().to(device)
    model.load_state_dict(torch.load(model_path))
    model.eval()
    print(f"Model loaded from {model_path}")
    return model

# Fungsi visualisasi heatmap dan indikator anomali
def visualize_heatmap_and_detect(model, image_tensor, original_image, threshold=0.01):  # Threshold rendah untuk sensitivitas tinggi
    """Visualisasi heatmap dan deteksi anomali dengan threshold rendah"""
    anomaly_map = model.compute_anomaly_map(image_tensor)
    
    # Hitung skor anomali maksimum
    max_score = np.max(anomaly_map)
    
    # Indikator anomali (threshold rendah agar mudah mendeteksi anomali kecil)
    is_anomaly = max_score > threshold
    anomaly_status = "Anomali Terdeteksi (Defect Kemungkinan Ada)" if is_anomaly else "Tidak Ada Anomali (Normal)"
    
    # Visualisasi
    fig, axes = plt.subplots(1, 3, figsize=(15, 5))
    
    # Gambar asli
    axes[0].imshow(original_image)
    axes[0].set_title('Gambar Asli')
    axes[0].axis('off')
    
    # Heatmap anomali
    im = axes[1].imshow(anomaly_map, cmap='hot', interpolation='bilinear')
    axes[1].set_title('Heatmap Anomali')
    axes[1].axis('off')
    plt.colorbar(im, ax=axes[1], fraction=0.046, pad=0.04)
    
    # Overlay heatmap pada gambar asli
    axes[2].imshow(original_image)
    axes[2].imshow(anomaly_map, cmap='hot', alpha=0.6, interpolation='bilinear')
    axes[2].set_title(f'Overlay Heatmap\nStatus: {anomaly_status}\nMax Score: {max_score:.4f}')
    axes[2].axis('off')
    
    plt.tight_layout()
    plt.show()
    
    print(f"Status: {anomaly_status} (Threshold: {threshold})")

# Main execution untuk inferensi
def inference_main():
    print("=== Inferensi EfficientAD-M pada Data Test ===")
    
    # Upload data test
    upload_test_data()
    
    # Create test dataset dan loader
    test_dataset = CustomTestDataset(root_dir='/content/test_data', transform=test_transform)
    test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=0)
    
    print(f"Test samples: {len(test_dataset)}")
    
    # Load model
    model = load_model()
    
    # Proses setiap gambar test
    for batch in test_loader:
        image_tensor = batch['image'].to(device)
        original_image = batch['original_image'][0]  # Ambil gambar asli untuk visualisasi
        image_path = batch['path'][0]
        
        print(f"\nMemproses: {image_path}")
        visualize_heatmap_and_detect(model, image_tensor, original_image)
    
    print("\n=== Inferensi Selesai ===")

# Jalankan inferensi
if __name__ == "__main__":
    try:
        inference_main()
    except Exception as e:
        print(f"Error in inference: {e}")
        print("Pastikan model telah dilatih dan disimpan di 'results/efficientad_model.pth', serta upload gambar test.")
