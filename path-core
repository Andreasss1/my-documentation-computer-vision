import os
import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
import torchvision.transforms as transforms
import torchvision.models as models
from torch.utils.data import Dataset, DataLoader
import cv2
from PIL import Image
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, roc_curve
from sklearn.neighbors import NearestNeighbors
from sklearn.random_projection import SparseRandomProjection
import warnings
warnings.filterwarnings('ignore')

# Install required packages
!pip install opencv-python-headless scikit-image faiss-cpu

# Check if GPU is available
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"Using device: {device}")

# Define paths
BASE_PATH = '/content/data'
TRAIN_PATH = os.path.join(BASE_PATH, 'train')
TEST_PATH = os.path.join(BASE_PATH, 'test')

class PatchCore:
    """
    PatchCore implementation for anomaly detection
    Uses pre-trained CNN features and memory bank for anomaly detection
    """
    def __init__(self, backbone='resnet18', layers=['layer2', 'layer3'], 
                 input_size=224, patch_size=3, stride=1):
        self.backbone_name = backbone
        self.layers = layers
        self.input_size = input_size
        self.patch_size = patch_size
        self.stride = stride
        self.device = device
        
        # Initialize feature extractor
        self.feature_extractor = self._build_feature_extractor()
        self.feature_extractor.eval()
        
        # Memory bank for normal features
        self.memory_bank = None
        self.nn_searcher = None
        
        # For dimension reduction
        self.dimension_reducer = None
        self.target_embed_dimension = 100
        
    def _build_feature_extractor(self):
        """Build pre-trained CNN feature extractor"""
        if self.backbone_name == 'resnet18':
            backbone = models.resnet18(pretrained=True)
        elif self.backbone_name == 'resnet50':
            backbone = models.resnet50(pretrained=True)
        elif self.backbone_name == 'wide_resnet50_2':
            backbone = models.wide_resnet50_2(pretrained=True)
        else:
            raise ValueError(f"Backbone {self.backbone_name} not supported")
        
        # Create feature extractor with intermediate layer outputs
        feature_extractor = IntermediateLayerGetter(backbone, self.layers)
        feature_extractor.to(self.device)
        
        return feature_extractor
    
    def _embed_features(self, features):
        """Embed features from multiple layers"""
        embeddings = []
        
        for layer_name in self.layers:
            layer_embedding = features[layer_name]
            layer_embedding = F.adaptive_avg_pool2d(layer_embedding, (self.input_size//16, self.input_size//16))
            
            # Reshape to patches
            batch_size, channels, height, width = layer_embedding.shape
            layer_embedding = layer_embedding.reshape(batch_size, channels, -1).permute(0, 2, 1)
            layer_embedding = layer_embedding.reshape(-1, channels)
            
            embeddings.append(layer_embedding)
        
        # Concatenate features from different layers
        embedding = torch.cat(embeddings, dim=1)
        return embedding
    
    def fit(self, train_loader):
        """Fit the model on normal training data"""
        print("Extracting features from training data...")
        
        all_embeddings = []
        
        with torch.no_grad():
            for i, (images, _, _) in enumerate(train_loader):
                images = images.to(self.device)
                
                # Extract features
                features = self.feature_extractor(images)
                embeddings = self._embed_features(features)
                
                all_embeddings.append(embeddings.cpu().numpy())
                
                if i % 10 == 0:
                    print(f"Processed {i+1}/{len(train_loader)} batches")
        
        # Concatenate all embeddings
        all_embeddings = np.concatenate(all_embeddings, axis=0)
        print(f"Total embeddings shape: {all_embeddings.shape}")
        
        # Reduce dimensions using random projection
        if all_embeddings.shape[1] > self.target_embed_dimension:
            print(f"Reducing dimensions from {all_embeddings.shape[1]} to {self.target_embed_dimension}")
            self.dimension_reducer = SparseRandomProjection(n_components=self.target_embed_dimension)
            all_embeddings = self.dimension_reducer.fit_transform(all_embeddings)
        
        # Core set sampling to reduce memory requirements
        print("Performing core set sampling...")
        if len(all_embeddings) > 1000:
            # Sample subset of embeddings as memory bank
            indices = np.random.choice(len(all_embeddings), 1000, replace=False)
            self.memory_bank = all_embeddings[indices]
        else:
            self.memory_bank = all_embeddings
        
        print(f"Memory bank size: {self.memory_bank.shape}")
        
        # Build nearest neighbor searcher
        self.nn_searcher = NearestNeighbors(n_neighbors=1, metric='euclidean')
        self.nn_searcher.fit(self.memory_bank)
        
        print("Training completed!")
    
    def predict(self, test_loader, return_feature_maps=False):
        """Predict anomaly scores for test data"""
        print("Computing anomaly scores...")
        
        all_scores = []
        all_labels = []
        all_paths = []
        all_feature_maps = []
        
        with torch.no_grad():
            for i, (images, labels, paths) in enumerate(test_loader):
                images = images.to(self.device)
                
                # Extract features
                features = self.feature_extractor(images)
                embeddings = self._embed_features(features)
                
                # Apply dimension reduction if fitted
                if self.dimension_reducer is not None:
                    embeddings_np = embeddings.cpu().numpy()
                    embeddings_np = self.dimension_reducer.transform(embeddings_np)
                else:
                    embeddings_np = embeddings.cpu().numpy()
                
                # Compute distances to nearest neighbors in memory bank
                distances, _ = self.nn_searcher.kneighbors(embeddings_np)
                
                # Reshape distances to spatial dimensions
                batch_size = images.shape[0]
                spatial_size = int(np.sqrt(embeddings_np.shape[0] // batch_size))
                
                for b in range(batch_size):
                    start_idx = b * (spatial_size * spatial_size)
                    end_idx = start_idx + (spatial_size * spatial_size)
                    
                    batch_distances = distances[start_idx:end_idx, 0]
                    score_map = batch_distances.reshape(spatial_size, spatial_size)
                    
                    # Resize to original image size
                    score_map_resized = cv2.resize(score_map, (self.input_size, self.input_size))
                    
                    # Overall anomaly score (max or mean of score map)
                    anomaly_score = np.max(score_map_resized)
                    
                    all_scores.append(anomaly_score)
                    all_labels.append(labels[b].item())
                    all_paths.append(paths[b])
                    
                    if return_feature_maps:
                        all_feature_maps.append(score_map_resized)
                
                if i % 20 == 0:
                    print(f"Processed {i+1}/{len(test_loader)} batches")
        
        if return_feature_maps:
            return np.array(all_scores), np.array(all_labels), all_paths, all_feature_maps
        else:
            return np.array(all_scores), np.array(all_labels), all_paths

class IntermediateLayerGetter(nn.Module):
    """Module to get intermediate layer outputs from a model"""
    def __init__(self, model, return_layers):
        super(IntermediateLayerGetter, self).__init__()
        self.model = model
        self.return_layers = return_layers
        
    def forward(self, x):
        outputs = {}
        
        # For ResNet models
        x = self.model.conv1(x)
        x = self.model.bn1(x)
        x = self.model.relu(x)
        x = self.model.maxpool(x)
        
        x = self.model.layer1(x)
        
        if 'layer1' in self.return_layers:
            outputs['layer1'] = x
            
        x = self.model.layer2(x)
        if 'layer2' in self.return_layers:
            outputs['layer2'] = x
            
        x = self.model.layer3(x)
        if 'layer3' in self.return_layers:
            outputs['layer3'] = x
            
        x = self.model.layer4(x)
        if 'layer4' in self.return_layers:
            outputs['layer4'] = x
        
        return outputs

class AnomalyDataset(Dataset):
    """Dataset class for anomaly detection"""
    def __init__(self, root_dir, transform=None, is_train=True):
        self.root_dir = root_dir
        self.transform = transform
        self.is_train = is_train
        self.images = []
        self.labels = []
        
        if is_train:
            # Training only uses normal images
            normal_dir = os.path.join(root_dir, 'normal')
            if os.path.exists(normal_dir):
                for img_name in os.listdir(normal_dir):
                    if img_name.lower().endswith(('.png', '.jpg', '.jpeg')):
                        self.images.append(os.path.join(normal_dir, img_name))
                        self.labels.append(0)  # Normal = 0
        else:
            # Testing uses both normal and defect images
            for class_name in ['normal', 'defect']:
                class_dir = os.path.join(root_dir, class_name)
                if os.path.exists(class_dir):
                    label = 0 if class_name == 'normal' else 1  # Normal = 0, Defect = 1
                    for img_name in os.listdir(class_dir):
                        if img_name.lower().endswith(('.png', '.jpg', '.jpeg')):
                            self.images.append(os.path.join(class_dir, img_name))
                            self.labels.append(label)
    
    def __len__(self):
        return len(self.images)
    
    def __getitem__(self, idx):
        img_path = self.images[idx]
        image = Image.open(img_path).convert('RGB')
        label = self.labels[idx]
        
        if self.transform:
            image = self.transform(image)
        
        return image, label, img_path

# Data transforms
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

# Create datasets
print("Creating datasets...")
train_dataset = AnomalyDataset(TRAIN_PATH, transform=transform, is_train=True)
test_dataset = AnomalyDataset(TEST_PATH, transform=transform, is_train=False)

print(f"Training samples: {len(train_dataset)}")
print(f"Testing samples: {len(test_dataset)}")

# Create data loaders
train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)

# Initialize PatchCore model
print("Initializing PatchCore model...")
model = PatchCore(backbone='wide_resnet50_2', layers=['layer2', 'layer3'])

# Train the model
model.fit(train_loader)

# Test the model and get feature maps for visualization
scores, labels, paths, feature_maps = model.predict(test_loader, return_feature_maps=True)

# Find optimal threshold using ROC curve
fpr, tpr, thresholds = roc_curve(labels, scores)
optimal_idx = np.argmax(tpr - fpr)
optimal_threshold = thresholds[optimal_idx]

print(f"Optimal threshold: {optimal_threshold:.4f}")

# Make predictions
predictions = (scores > optimal_threshold).astype(int)

# Calculate metrics
auc_score = roc_auc_score(labels, scores)
accuracy = np.mean(predictions == labels)

print(f"AUC Score: {auc_score:.4f}")
print(f"Accuracy: {accuracy:.4f}")

# Visualization function
def visualize_results(n_samples=6):
    """Visualize anomaly detection results with heatmaps"""
    
    # Get sample indices for visualization
    normal_indices = np.where(labels == 0)[0]
    defect_indices = np.where(labels == 1)[0]
    
    sample_indices = []
    sample_indices.extend(normal_indices[:n_samples//2] if len(normal_indices) >= n_samples//2 else normal_indices)
    sample_indices.extend(defect_indices[:n_samples//2] if len(defect_indices) >= n_samples//2 else defect_indices)
    
    fig, axes = plt.subplots(3, len(sample_indices), figsize=(4*len(sample_indices), 12))
    fig.suptitle('PatchCore Anomaly Detection Results', fontsize=16)
    
    if len(sample_indices) == 1:
        axes = axes.reshape(-1, 1)
    
    for i, idx in enumerate(sample_indices):
        # Load original image
        img_path = paths[idx]
        original_img = Image.open(img_path).convert('RGB')
        original_img = original_img.resize((224, 224))
        
        # Original image
        axes[0, i].imshow(original_img)
        axes[0, i].set_title(f'Original\nLabel: {"Defect" if labels[idx] == 1 else "Normal"}')
        axes[0, i].axis('off')
        
        # Anomaly score map
        score_map = feature_maps[idx]
        im1 = axes[1, i].imshow(score_map, cmap='jet')
        axes[1, i].set_title(f'Anomaly Map\nScore: {scores[idx]:.3f}')
        axes[1, i].axis('off')
        plt.colorbar(im1, ax=axes[1, i], fraction=0.046, pad=0.04)
        
        # Overlay heatmap on original
        axes[2, i].imshow(original_img)
        im2 = axes[2, i].imshow(score_map, cmap='jet', alpha=0.5)
        axes[2, i].set_title(f'Overlay\nPred: {"Defect" if predictions[idx] == 1 else "Normal"}')
        axes[2, i].axis('off')
    
    plt.tight_layout()
    plt.show()

# Visualize results
visualize_results(n_samples=6)

# Confusion Matrix
cm = confusion_matrix(labels, predictions)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
            xticklabels=['Normal', 'Defect'], 
            yticklabels=['Normal', 'Defect'])
plt.title('Confusion Matrix - PatchCore')
plt.ylabel('True Label')
plt.xlabel('Predicted Label')
plt.show()

# Classification Report
print("\nClassification Report:")
print(classification_report(labels, predictions, target_names=['Normal', 'Defect']))

# ROC Curve
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC Curve (AUC = {auc_score:.2f})')
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve - PatchCore')
plt.legend(loc="lower right")
plt.show()

# Score distribution
plt.figure(figsize=(10, 6))
plt.hist(scores[labels == 0], bins=30, alpha=0.7, label='Normal', color='blue', density=True)
plt.hist(scores[labels == 1], bins=30, alpha=0.7, label='Defect', color='red', density=True)
plt.axvline(optimal_threshold, color='black', linestyle='--', label=f'Threshold: {optimal_threshold:.3f}')
plt.xlabel('Anomaly Score')
plt.ylabel('Density')
plt.title('Distribution of Anomaly Scores - PatchCore')
plt.legend()
plt.show()

# Feature map statistics
print(f"\nFeature Map Statistics:")
print(f"- Min anomaly score: {np.min(scores):.4f}")
print(f"- Max anomaly score: {np.max(scores):.4f}")
print(f"- Mean anomaly score: {np.mean(scores):.4f}")
print(f"- Std anomaly score: {np.std(scores):.4f}")

print(f"\nSummary:")
print(f"- Total test samples: {len(labels)}")
print(f"- Normal samples: {np.sum(labels == 0)}")
print(f"- Defect samples: {np.sum(labels == 1)}")
print(f"- AUC Score: {auc_score:.4f}")
print(f"- Accuracy: {accuracy:.4f}")
print(f"- Optimal threshold: {optimal_threshold:.4f}")

# Additional visualization: Top anomalous regions
def show_top_anomalies(n_top=4):
    """Show images with highest anomaly scores"""
    top_indices = np.argsort(scores)[-n_top:][::-1]
    
    fig, axes = plt.subplots(2, n_top, figsize=(4*n_top, 8))
    fig.suptitle('Top Anomalous Regions', fontsize=16)
    
    if n_top == 1:
        axes = axes.reshape(-1, 1)
    
    for i, idx in enumerate(top_indices):
        # Load original image
        img_path = paths[idx]
        original_img = Image.open(img_path).convert('RGB')
        original_img = original_img.resize((224, 224))
        
        # Original image
        axes[0, i].imshow(original_img)
        axes[0, i].set_title(f'Rank {i+1}\nScore: {scores[idx]:.3f}\nLabel: {"Defect" if labels[idx] == 1 else "Normal"}')
        axes[0, i].axis('off')
        
        # Heatmap overlay
        score_map = feature_maps[idx]
        axes[1, i].imshow(original_img)
        im = axes[1, i].imshow(score_map, cmap='jet', alpha=0.6)
        axes[1, i].set_title(f'Heatmap Overlay')
        axes[1, i].axis('off')
        plt.colorbar(im, ax=axes[1, i], fraction=0.046, pad=0.04)
    
    plt.tight_layout()
    plt.show()

show_top_anomalies(n_top=4)
