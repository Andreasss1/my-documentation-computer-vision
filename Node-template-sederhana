import cv2
import numpy as np
from ultralytics import YOLO
import base64
import json

# Load YOLO model
model = YOLO('best.pt')

# Initialize camera
cap = cv2.VideoCapture(0)

if not cap.isOpened():
    msg['payload'] = {"error": "Cannot open camera"}
    return msg

# Read frame
ret, frame = cap.read()
if not ret:
    msg['payload'] = {"error": "Cannot read frame"}
    return msg

# Run YOLO inference
results = model(frame)

# Draw results on frame
annotated_frame = results[0].plot()

# Convert to base64 for web display
_, buffer = cv2.imencode('.jpg', annotated_frame)
img_base64 = base64.b64encode(buffer).decode('utf-8')

# Prepare detection data
detections = []
for r in results:
    boxes = r.boxes
    if boxes is not None:
        for box in boxes:
            detections.append({
                "class": int(box.cls[0]),
                "confidence": float(box.conf[0]),
                "bbox": box.xyxy[0].tolist()
            })

cap.release()

msg['payload'] = {
    "image": f"data:image/jpeg;base64,{img_base64}",
    "detections": detections
}

return msg

// templates: 
<div ng-bind-html="msg.payload.html">
    <h3>YOLO Object Detection</h3>
    <div id="detection-container">
        <img ng-if="msg.payload.image" 
             ng-src="{{msg.payload.image}}" 
             style="max-width: 100%; height: auto;">
        
        <div ng-if="msg.payload.detections">
            <h4>Detections: {{msg.payload.detections.length}}</h4>
            <ul>
                <li ng-repeat="det in msg.payload.detections">
                    Class: {{det.class}}, 
                    Confidence: {{(det.confidence * 100).toFixed(1)}}%
                </li>
            </ul>
        </div>
    </div>
</div>

<script>
(function(scope) {
    scope.$watch('msg', function(newVal) {
        if (newVal && newVal.payload) {
            // Update image and detection info
        }
    });
})(scope);
</script>
