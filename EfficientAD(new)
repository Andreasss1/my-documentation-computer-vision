import numpy as np
import tifffile
import torch
from torch.utils.data import DataLoader, Dataset
from torchvision import transforms
from PIL import Image
import argparse
import itertools
import os
import random
from tqdm import tqdm
import glob
from sklearn.metrics import roc_auc_score

# Implementasi sederhana untuk kelas-kelas yang diperlukan
class ImageFolderCustom(Dataset):
    def __init__(self, root_dir, transform=None):
        self.root_dir = root_dir
        self.transform = transform
        self.images = []
        
        # Ambil semua file gambar dari folder
        extensions = ['*.jpg', '*.jpeg', '*.png', '*.bmp', '*.tiff', '*.tif']
        for ext in extensions:
            self.images.extend(glob.glob(os.path.join(root_dir, ext)))
            self.images.extend(glob.glob(os.path.join(root_dir, ext.upper())))
    
    def __len__(self):
        return len(self.images)
    
    def __getitem__(self, idx):
        img_path = self.images[idx]
        image = Image.open(img_path).convert('RGB')
        
        if self.transform:
            return self.transform(image)
        return image

class InfiniteDataloader:
    def __init__(self, dataloader):
        self.dataloader = dataloader
        self.iterator = iter(self.dataloader)
    
    def __iter__(self):
        return self
    
    def __next__(self):
        try:
            return next(self.iterator)
        except StopIteration:
            self.iterator = iter(self.dataloader)
            return next(self.iterator)

# Implementasi arsitektur PDN sederhana (lebih ringan untuk CPU)
class PDN(torch.nn.Module):
    def __init__(self, out_channels):
        super(PDN, self).__init__()
        self.feature_extractor = torch.nn.Sequential(
            torch.nn.Conv2d(3, 32, 3, padding=1),      # Kurangi channel
            torch.nn.ReLU(),
            torch.nn.Conv2d(32, 64, 3, padding=1),
            torch.nn.ReLU(),
            torch.nn.MaxPool2d(2),
            torch.nn.Conv2d(64, 128, 3, padding=1),
            torch.nn.ReLU(),
            torch.nn.Conv2d(128, out_channels, 3, padding=1),
            torch.nn.ReLU()
        )
    
    def forward(self, x):
        return self.feature_extractor(x)

# Implementasi Autoencoder sederhana (lebih ringan untuk CPU)
class AutoEncoder(torch.nn.Module):
    def __init__(self, out_channels):
        super(AutoEncoder, self).__init__()
        self.encoder = torch.nn.Sequential(
            torch.nn.Conv2d(3, 32, 3, padding=1),      # Kurangi channel
            torch.nn.ReLU(),
            torch.nn.Conv2d(32, 64, 3, padding=1),
            torch.nn.ReLU(),
            torch.nn.MaxPool2d(2),
            torch.nn.Conv2d(64, out_channels, 3, padding=1),
            torch.nn.ReLU()
        )
        self.decoder = torch.nn.Sequential(
            torch.nn.Conv2d(out_channels, 64, 3, padding=1),
            torch.nn.ReLU(),
            torch.nn.Upsample(scale_factor=2, mode='bilinear', align_corners=False),
            torch.nn.Conv2d(64, 32, 3, padding=1),
            torch.nn.ReLU(),
            torch.nn.Conv2d(32, out_channels, 3, padding=1),
            torch.nn.ReLU()
        )
    
    def forward(self, x):
        encoded = self.encoder(x)
        decoded = self.decoder(encoded)
        return decoded

def get_argparse():
    parser = argparse.ArgumentParser()
    parser.add_argument('-d', '--data_path', default='data/train',
                        help='Path to training data folder')
    parser.add_argument('-o', '--output_dir', default='output/models')
    parser.add_argument('-t', '--train_steps', type=int, default=10000)  # Kurangi untuk CPU
    parser.add_argument('--image_size', type=int, default=128)  # Kurangi ukuran untuk CPU
    parser.add_argument('--batch_size', type=int, default=2)   # Kurangi batch size untuk CPU
    parser.add_argument('--learning_rate', type=float, default=1e-4)
    parser.add_argument('--num_workers', type=int, default=0)  # Tambahkan opsi num_workers
    return parser.parse_args()

# Constants
seed = 42
# Force CPU usage - lebih aman untuk memastikan
on_gpu = False  # Set ke False untuk memastikan pakai CPU saja
out_channels = 256  # Kurangi channel untuk CPU

def train_transform(image, image_size):
    """Transform untuk training dengan augmentasi"""
    base_transform = transforms.Compose([
        transforms.Resize((image_size, image_size)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])
    
    aug_transform = transforms.Compose([
        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),
        transforms.Resize((image_size, image_size)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])
    
    return base_transform(image), aug_transform(image)

@torch.no_grad()
def teacher_normalization(teacher, train_loader):
    """Normalisasi teacher features"""
    print("Computing teacher normalization...")
    teacher.eval()
    
    mean_outputs = []
    for batch in tqdm(train_loader, desc='Computing mean of features'):
        if isinstance(batch, tuple):
            train_image = batch[0]  # Jika ada augmented pair
        else:
            train_image = batch
            
        # Semua tensor di CPU - tidak perlu .cuda()
        teacher_output = teacher(train_image)
        mean_output = torch.mean(teacher_output, dim=[0, 2, 3])
        mean_outputs.append(mean_output)
    
    channel_mean = torch.mean(torch.stack(mean_outputs), dim=0)
    channel_mean = channel_mean[None, :, None, None]

    mean_distances = []
    for batch in tqdm(train_loader, desc='Computing std of features'):
        if isinstance(batch, tuple):
            train_image = batch[0]
        else:
            train_image = batch
            
        # Semua tensor di CPU - tidak perlu .cuda()
        teacher_output = teacher(train_image)
        distance = (teacher_output - channel_mean) ** 2
        mean_distance = torch.mean(distance, dim=[0, 2, 3])
        mean_distances.append(mean_distance)
    
    channel_var = torch.mean(torch.stack(mean_distances), dim=0)
    channel_var = channel_var[None, :, None, None]
    channel_std = torch.sqrt(channel_var)

    return channel_mean, channel_std

def main():
    # Set random seeds
    torch.manual_seed(seed)
    np.random.seed(seed)
    random.seed(seed)
    
    # Parse arguments
    config = get_argparse()
    
    print(f"Training on: CPU (Forced)")
    print("INFO: All operations will run on CPU")
    print("- Reduced image size to 128x128")
    print("- Reduced batch size to 2") 
    print("- Reduced training steps to 10,000")
    print("- Reduced model complexity")
    print(f"Data path: {config.data_path}")
    print(f"Output directory: {config.output_dir}")
    print(f"Training steps: {config.train_steps}")
    
    # Create output directory
    os.makedirs(config.output_dir, exist_ok=True)
    
    # Load training data
    print("Loading training data...")
    train_dataset = ImageFolderCustom(
        config.data_path, 
        transform=lambda x: train_transform(x, config.image_size)
    )
    
    print(f"Found {len(train_dataset)} training images")
    
    if len(train_dataset) == 0:
        print("Error: No images found in the training directory!")
        print(f"Please check if {config.data_path} contains image files")
        return
    
    # Split data for validation (10% for validation)
    train_size = int(0.9 * len(train_dataset))
    val_size = len(train_dataset) - train_size
    
    train_subset, val_subset = torch.utils.data.random_split(
        train_dataset, [train_size, val_size], 
        generator=torch.Generator().manual_seed(seed)
    )
    
    train_loader = DataLoader(
        train_subset, batch_size=config.batch_size, 
        shuffle=True, num_workers=config.num_workers, pin_memory=False  # Disable pin_memory untuk CPU
    )
    
    val_loader = DataLoader(
        val_subset, batch_size=1, shuffle=False, num_workers=config.num_workers
    )
    
    train_loader_infinite = InfiniteDataloader(train_loader)
    
    print(f"Training set: {len(train_subset)} images")
    print(f"Validation set: {len(val_subset)} images")
    
    # Create models
    print("Creating models...")
    teacher = PDN(out_channels)
    student = PDN(2 * out_channels)
    autoencoder = AutoEncoder(out_channels)
    
    # Initialize teacher with random weights (dalam implementasi asli, teacher di-pretrain)
    print("Initializing teacher model...")
    teacher.eval()
    student.train()
    autoencoder.train()
    
    # Semua model di CPU - tidak perlu .cuda()
    print("All models running on CPU")
    
    # Compute teacher normalization
    teacher_mean, teacher_std = teacher_normalization(teacher, train_loader)
    
    # Setup optimizer
    optimizer = torch.optim.Adam(
        itertools.chain(student.parameters(), autoencoder.parameters()),
        lr=config.learning_rate, weight_decay=1e-5
    )
    
    scheduler = torch.optim.lr_scheduler.StepLR(
        optimizer, step_size=int(0.95 * config.train_steps), gamma=0.1
    )
    
    # Training loop
    print("Starting training...")
    teacher.eval()  # Teacher tetap dalam mode eval
    
    tqdm_obj = tqdm(range(config.train_steps))
    for iteration in tqdm_obj:
        try:
            batch = next(train_loader_infinite)
            if isinstance(batch, tuple) and len(batch) == 2:
                image_st, image_ae = batch
            else:
                # Jika tidak ada augmented pair, gunakan image yang sama
                image_st = image_ae = batch
                
            # Semua tensor di CPU - tidak perlu .cuda()
            
            # Teacher prediction (frozen)
            with torch.no_grad():
                teacher_output_st = teacher(image_st)
                teacher_output_st = (teacher_output_st - teacher_mean) / teacher_std
                teacher_output_ae = teacher(image_ae)
                teacher_output_ae = (teacher_output_ae - teacher_mean) / teacher_std
            
            # Student predictions
            student_output_st = student(image_st)[:, :out_channels]
            student_output_ae = student(image_ae)[:, out_channels:]
            
            # Autoencoder prediction
            ae_output = autoencoder(image_ae)
            
            # Compute losses
            distance_st = (teacher_output_st - student_output_st) ** 2
            d_hard = torch.quantile(distance_st, q=0.999)
            loss_hard = torch.mean(distance_st[distance_st >= d_hard])
            
            distance_ae = (teacher_output_ae - ae_output) ** 2
            loss_ae = torch.mean(distance_ae)
            
            distance_stae = (ae_output - student_output_ae) ** 2
            loss_stae = torch.mean(distance_stae)
            
            loss_total = loss_hard + loss_ae + loss_stae
            
            # Backward pass
            optimizer.zero_grad()
            loss_total.backward()
            optimizer.step()
            scheduler.step()
            
            # Update progress
            if iteration % 10 == 0:
                tqdm_obj.set_description(f"Loss: {loss_total.item():.4f}")
            
            # Save intermediate models
            if iteration % 5000 == 0 and iteration > 0:
                torch.save(teacher.state_dict(), 
                          os.path.join(config.output_dir, f'teacher_step_{iteration}.pth'))
                torch.save(student.state_dict(), 
                          os.path.join(config.output_dir, f'student_step_{iteration}.pth'))
                torch.save(autoencoder.state_dict(), 
                          os.path.join(config.output_dir, f'autoencoder_step_{iteration}.pth'))
                print(f"\nSaved models at step {iteration}")
        
        except Exception as e:
            print(f"Error at iteration {iteration}: {str(e)}")
            continue
    
    # Save final models
    print("Saving final models...")
    torch.save(teacher.state_dict(), 
              os.path.join(config.output_dir, 'teacher_final.pth'))
    torch.save(student.state_dict(), 
              os.path.join(config.output_dir, 'student_final.pth'))
    torch.save(autoencoder.state_dict(), 
              os.path.join(config.output_dir, 'autoencoder_final.pth'))
    
    # Save normalization parameters
    torch.save({
        'teacher_mean': teacher_mean,
        'teacher_std': teacher_std,
        'out_channels': out_channels,
        'image_size': config.image_size
    }, os.path.join(config.output_dir, 'normalization_params.pth'))
    
    print("Training completed!")
    print(f"Models saved in: {config.output_dir}")

if __name__ == '__main__':
    main()
